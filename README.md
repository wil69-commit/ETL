# ğŸš€ Projet ETL avec Apache Airflow & MongoDB

![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.7+-blue?logo=apacheairflow)
![Python](https://img.shields.io/badge/Python-3.7%2B-yellow?logo=python)
![MongoDB](https://img.shields.io/badge/MongoDB-Database-green?logo=mongodb)
![License](https://img.shields.io/badge/license-MIT-lightgrey)
![Status](https://img.shields.io/badge/status-Completed-success)

---

## Description du projet

Ce projet met en place un **pipeline ETL automatisÃ©** (Extraction, Transformation, Chargement) Ã  lâ€™aide de **Apache Airflow**, connectÃ© Ã  une base de donnÃ©es **MongoDB Compass**.

Le pipeline permet :
- dâ€™**extraire** les donnÃ©es brutes depuis MongoDB,
- de les **nettoyer et transformer** avec **Pandas**,
- de **charger** les donnÃ©es nettoyÃ©es dans une nouvelle base MongoDB,
- dâ€™**exporter** les rÃ©sultats sous forme de fichier CSV,
- et dâ€™**envoyer une notification par email** Ã  la fin du processus.

---

## âš™ï¸ Technologies utilisÃ©es

| Outil / Librairie | RÃ´le |
|--------------------|------|
| **Apache Airflow** | Orchestration et automatisation du pipeline |
| **MongoDB Compass** | Base de donnÃ©es NoSQL source et cible |
| **Python (Pandas)** | Traitement et nettoyage des donnÃ©es |
| **SMTP / Gmail** | Notification de fin de traitement |
| **Docker** | Environnement isolÃ© et reproductible |

---

## ğŸ§© Architecture du projet

```plaintext
ğŸ“ airflow/
 â”œâ”€â”€ dags/
 â”‚   â””â”€â”€ Amazone_DAG.py         # Code principal du pipeline Airflow
 â”œâ”€â”€ data/
 â”‚   â”œâ”€â”€ Amazone.csv            # DonnÃ©es extraites
 â”‚   â””â”€â”€ Amazone_clean.csv      # DonnÃ©es nettoyÃ©es
 â”œâ”€â”€ docker-compose.yaml        # Configuration Docker dâ€™Airflow
 â””â”€â”€ requirements.txt           # DÃ©pendances Python (pymongo, pandas, etc.)

